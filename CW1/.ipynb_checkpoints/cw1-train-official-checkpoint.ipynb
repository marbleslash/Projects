{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1: Train a Sentiment Analysis Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and take a quick look\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv('coursework1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry num 40000\n",
      "num of pos entries 20000\n",
      "num of neg entries 20000\n"
     ]
    }
   ],
   "source": [
    "# check the size of the data and its class distribution\n",
    "all_text = raw_data['text'].tolist()\n",
    "all_lables = raw_data['sentiment'].tolist()\n",
    "\n",
    "\n",
    "print('entry num', len(all_text))\n",
    "print('num of pos entries', len([l for l in all_lables if l=='pos']))\n",
    "print('num of neg entries', len([l for l in all_lables if l=='neg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the split given by the Professor. We do not really use this split. We will end up cross-validating.\n",
    "train_text = all_text[:35000]\n",
    "train_labels = all_lables[:35000]\n",
    "test_text = all_text[35000:]\n",
    "test_labels = all_lables[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning and Preprocessing:\n",
    "In this sample code I do not perform any text normalization/pre-processing on the text. However, using the tdf-idf  text pre-processor yields better results. So, we will just use the tdf-idf Vectorizer for lowercasing, splitting the the text, and removing punctuation and specifying the stop words to be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lowercase_text = []\n",
    "for text in (raw_data['text']): \n",
    "    lowercase_text.append(re.sub(puncs, \"\",  text.lower())   )\n",
    "    #lowercase_text.append(text.lower())\n",
    "\n",
    "raw_copy = raw_data.copy()\n",
    "raw_copy['lowercase_text'] = lowercase_text\n",
    "neg_sent = raw_copy[raw_copy['sentiment'] == 'neg']\n",
    "pos_sent = raw_copy[raw_copy['sentiment'] == 'pos']\n",
    "\n",
    "neg_sent_combined = \"\"\n",
    "for sent in neg_sent['lowercase_text'][1:10000]:\n",
    "    neg_sent_combined = neg_sent_combined + \" \" + sent\n",
    "\n",
    "pos_sent_combined = \"\"\n",
    "for sent in pos_sent['lowercase_text'][1:10000]:\n",
    "     pos_sent_combined = pos_sent_combined + \" \" + sent\n",
    "    \n",
    "\n",
    "neg_splits = neg_sent_combined.split()\n",
    "pos_splits = pos_sent_combined.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Determine Which Stop Words to Remove\n",
    "#### Read the PDF under \"Why Stop Words should be Kept\" to understand process of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1208-5eea22224466>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1208-5eea22224466>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    5\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Getting a distribution of the stop words for negative sentiment and positive sentiment \n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Specifying the stop words with the stopwords package\n",
    "stop_words = set(stopwords.words('english'))\n",
    "list_stops = list(stop_words)\n",
    "\n",
    "# Getting a dictionary for the distribution of all words for the positive and negative texts respectively\n",
    "neg_dict = Counter(neg_splits)\n",
    "pos_dict = Counter(pos_splits)\n",
    "\n",
    "# Converting the dictionaries to list\n",
    "neg_list = [(k,v) for k,v in neg_dict.items()]\n",
    "pos_list = [(k,v) for k,v in pos_dict.items()]\n",
    "\n",
    "# Getting a list of the distribution of only the stop worsd\n",
    "neg_stops = [tup for tup in neg_list if tup[0] in list_stops]\n",
    "pos_stops = [tup for tup in pos_list if tup[0] in list_stops]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4737236567002008 0.46778368733190817\n"
     ]
    }
   ],
   "source": [
    "# This number compares the proportion of total words (by frequency) stop words have in\n",
    "# negative sentiment text (on left) vs positive sentiment texts (on right.)\n",
    "\n",
    "neg_stops_sum = sum([tup[1] for tup in neg_stops])\n",
    "neg_words_sum = sum([tup[1] for tup in neg_list])\n",
    "pos_stops_sum = sum([tup[1] for tup in pos_stops])\n",
    "pos_words_sum = sum([tup[1] for tup in pos_list])\n",
    "print(neg_stops_sum/neg_words_sum, pos_stops_sum/pos_words_sum)\n",
    "\n",
    "## As you can see below, the negative text has a higher proportion of stop words than does postive text\n",
    "## This might be an indicator that stop words to in fact make a difference in classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Obtaining a list of stop words sorted by frequency for both the positive text and the negative text \n",
    "\n",
    "# The stop words in the negative and positive texts respectively\n",
    "neg_stops_words = [i[0] for i in neg_stops]\n",
    "pos_stops_words = [i[0] for i in pos_stops]\n",
    "\n",
    "# Obtaining the stop words that only appear in the negative text and not the positive text\n",
    "only_in_neg = [i for i in sorted(neg_stops_words) if i not in sorted(pos_stops_words)]\n",
    "\n",
    "# Obtaining the stop words that only appear in the positive text and not the negative text\n",
    "only_in_pos = [i for i in sorted(pos_stops_words) if i not in sorted(neg_stops_words)]\n",
    "\n",
    "# Obtaining the stop words to be dropped because they only appear in one of the positive or negative texts\n",
    "# We are trying to visualize the data, that is why we are dropping these stop words (we do not actually drop them \n",
    "# in the final tdf-idf vectorized data)\n",
    "drop_words = only_in_neg + only_in_pos\n",
    "neg_stops_equal = [tup for tup in neg_stops if tup[0] not in drop_words]\n",
    "pos_stops_equal = [tup for tup in pos_stops if tup[0] not in drop_words]\n",
    "\n",
    "neg_stops_equal = sorted(neg_stops_equal, key=lambda x: x[0])\n",
    "pos_stops_equal = sorted(pos_stops_equal, key=lambda x: x[0])\n",
    "n = neg_stops_equal\n",
    "p = pos_stops_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Explanation of Code thus Far\n",
    "\n",
    "The stop words defined as \"early stops\" are the stop words that when removed, yield improvements to accuracy. These are organized in order of the stop words that the least different in terms of proportion frequency  in the positive and negative sentiment texts respectively. For instance, if the word \"the\" has a 15% appearance rate in positive sentiment and 15% appearance rate in negative, there is little difference between the two. Thus, it is unlikely the is an important word to determine between positive and negative texts and can thus be removed. However, if, for instance, \"only\" appeared 5% in negative and 10% in positive. This difference is larger and it would probably be best to keep \"only\" as a stop word.\n",
    "\n",
    "###### Further explanation can be found in the PDF under the \"Why Stop Words Should be Kept\" Section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# My arbitrary list of stop words that I want to remove. I do NOT want to remove all the possible stopwords, as this\n",
    "# results in a reduction in accuracy. \n",
    "easy_stops = ['the', 'a', 'and', 'of', 'to', 'is', 'in', 'it', 'this', 'i', 'are', 'an', \"it's\", \"me\", \"they\",\"they're\", 'we', 'am'\\\n",
    "             'its', 'be', 'from', 'how']\n",
    "\n",
    "# Getting the stop word plus frequencies in the negative and positive texts, combined in a tuple\n",
    "stops = [(n[i][0], n[i][1], p[i][1]) for i in range(len(n))]\n",
    "\n",
    "# Getting only the stop words as specified above\n",
    "stops_easy = [i for i in stops if i[0] in easy_stops]\n",
    "\n",
    "# Getting the ratio of the stop words (as percent difference)\n",
    "stops_easy_ratios = [(i[0],   abs(i[1] - i[2])/(i[1] + i[2])) for i in stops_easy]\n",
    "\n",
    "# Getting only the percentages without the keys\n",
    "ratios = [i[1] for i in stops_easy_ratios]\n",
    "\n",
    "# The maximum percentage value in the easy_stops list (This functions as a threshold, baseline value)\n",
    "# If any percentage exceeds this value, it may be too significant a stop word to remove\n",
    "max_ratio = max(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b87226e80>"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the stop words as defined by the ntlk package\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "list_stops = list(stop_words)\n",
    "\n",
    "# Below is a ratio difference of stop words between positive and negative sentiment, arranged alphabetically\n",
    "all_ratios =  [(i[0],   abs(i[1] - i[2])/(i[2])) for i in stops]\n",
    "\n",
    "# Only includes the stop words that do not mass a certain threshold\n",
    "all_ratios_maxed = [i for i in all_ratios if i[1] <= max_ratio]\n",
    "\n",
    "# Sorting the ratio from smallest to largest\n",
    "all_ratios_sorted = sorted(all_ratios_maxed, key = lambda x: x[1])\n",
    "easy_stops2 = [i for i in (all_ratios_sorted) if i[0] not in easy_stops]\n",
    "all_ratios_sorted_words = [i[0] for i in all_ratios_sorted]\n",
    "all_ratios_sorted_vals = [i[1] for i in all_ratios_sorted]\n",
    "\n",
    "\n",
    "# Obtaining the proportion for each stop word in negative text\n",
    "negs = [i[1]/nsum for i in stops]\n",
    "\n",
    "# Obtaining the proportion for each stop word in positive text\n",
    "posivs = [i[2]/psum for i in stops]\n",
    "\n",
    "# Obtaining all the list of stop words\n",
    "wrds = [i[0] for i in stops]\n",
    "\n",
    "# The indices of the words with the smallest percent difference between negative and positive text\n",
    "neg2 = np.array(negs)[np.array([122,42,11,25,88,150,0,67,34,53])]\n",
    "posivs2 = np.array(posivs)[np.array([122,42,11,25,88,150,0,67,34,53])]\n",
    "wrds2 = np.array(wrds)[np.array([122,42,11,25,88,150,0,67,34,53])]\n",
    "\n",
    "\n",
    "# Plotting the top stop words that show very little difference in frequency between positive and negative text\n",
    "plt.title('Percentage of Stop Words in Positive and Negative Text')\n",
    "a = np.array([0,2,4,6,8,10,12,16,18,20])\n",
    "plt.bar(a - 0.4, neg2)\n",
    "plt.bar(a + 0.4, posivs2)\n",
    "plt.xticks(a, ['these', \"further\", \"are\", \"it\", \"can\", \"on\", \"won't\", \"a\", \"it's\", \"don\", \"here\"])\n",
    "plt.legend(['Negative', 'Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging and How Tags Play a Role in Predicting Sentiment\n",
    "\n",
    "#### This section is explained under the \"Why Lemmatizing and Stemming May not be a Good Idea\" section of the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b871c2fd0>"
      ]
     },
     "execution_count": 1260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploring all of the POS tagging \n",
    "\n",
    "# Getting the POS tags for the negative and positive labels\n",
    "neg_pos = nltk.pos_tag(neg_splits)\n",
    "pos_pos = nltk.pos_tag(pos_splits)\n",
    "\n",
    "# Getting the tags only, without the word\n",
    "neg_tags = [i[1] for i in neg_pos]\n",
    "pos_tags = [i[1] for i in pos_pos]\n",
    "\n",
    "# Getting the distribution of POS tags for the respective labels\n",
    "neg_tag_count  = Counter(neg_tags)\n",
    "pos_tag_count = Counter(pos_tags)\n",
    "\n",
    "##sorted(pos_stops_equal, key=lambda x: x[0])\n",
    "##neg_list = [(k,v) for k,v in neg_dict.items()]\n",
    "\n",
    "\n",
    "# Getting the POS tags for the negative labels\n",
    "neg_pos_tags = [(k,v) for k,v in neg_tag_count.items()]\n",
    "\n",
    "# Getting the POS tags for the positive labels\n",
    "pos_pos_tags = [(k,v) for k,v in pos_tag_count.items()]\n",
    "\n",
    "\n",
    "# Sorting the pos tags by the second index for the respective labels\n",
    "neg_sort = sorted(neg_pos_tags, key=lambda x: x[0])\n",
    "pos_sort = sorted(pos_pos_tags, key=lambda x: x[0])\n",
    "all_tags = [i[0] for i in neg_sort]\n",
    "pos_nums = [i[1] for i in pos_sort if i[0] in all_tags]\n",
    "neg_nums = [i[1] for i in neg_sort]\n",
    "\n",
    "\n",
    "# Total number of tokens in positive and negative labels\n",
    "psum = sum(pos_nums)\n",
    "nsum = sum(neg_nums)\n",
    "\n",
    "# Plotting a graph that compares the POS distribution of verbs for positive and negative labels\n",
    "x = ('VD','VBD', \"VBG\", \"VBN\", \"VBP\", \"VBZ\")\n",
    "place_x = np.array([1,3,5,7,9,11])\n",
    "plt.title(\"% Distribution of POS tags (verbs)\")\n",
    "plt.bar(place_x - 0.405, np.array(neg_nums[29:35])/psum, alpha = 1)\n",
    "plt.bar(place_x + 0.405, np.array(pos_nums[29:35])/nsum, alpha = 1)\n",
    "plt.xticks(place_x, x)\n",
    "plt.legend(['Negative', 'Positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For a description of the graph above, please refer to \"Why Lemmatizing and Stemming May not be a Good Idea\" in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Step: Description of the Cell Below \n",
    "\n",
    "In the next cell below we perform 5 fold cross-validation on the data in order to evaluate our hyperparameters.\n",
    "\n",
    "Here are the steps we follow:\n",
    "\n",
    "##### Step 1) Set the max_feature_number = 100000\n",
    "\n",
    "    Why we do this: as mentioned in the report (pdf file), there are simply so many features due to a combination of ngrams and the vocabulary itself that setting this number too low would ultimately remove many features that could end up being important.\n",
    "    \n",
    "##### Step 2) We choose a small subset of stopwords to remove\n",
    "    \n",
    "    How we do this: as mentioned in the pdf, we take the top 50 or so stop words determined by the percent difference as described in the PDF, and remove them one by one. If removing a words yields an improvement to accuracy to our cross validated sets, then we will keep this removal. This algorithm is somewhat sequential and will not necessarily remove all the stop words that could help improve accuracy.\n",
    "    \n",
    "##### Step 3) TfidfVectorizer\n",
    "    We use the TfidfVectorizer, which will clean the data for us: removing most punctuation marks and lowercasing the words. We also apply a log transformation on the data with the sublinear_tf = True because the data is far from uniform. Doing so indeed gives us better results. In addition, we tell TfidfVectorizer to remove the stop words we want it to by providing a specific list of stop words.\n",
    "\n",
    "##### Step 4) Fitting the Logistic Regression\n",
    "    We then fit the logistic Regression with l2 loss using C = 18.80 on the data and proceed to cross validate.\n",
    "    \n",
    "##### Step 5) Cross-Validation\n",
    "    This step allows us to tune the hyperparameters and allows to evaluate whether the model is performing at the level we want it to or not.\n",
    "    \n",
    "##### Step 6) Printing the Results\n",
    "    Here we see are accuracy, precision, and recall. All of the values are close, this is due in part because there is generally a 50/50 split in both the training and validation sets when we cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['re', 'shan', 'she', 'shouldn'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['re', 'shan', 'she', 'shouldn'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9126249999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#*************************************#\n",
    "################ STEP 1 ###############\n",
    "#*************************************#\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_feature_num = 100000\n",
    "\n",
    "\n",
    "#*************************************#\n",
    "################ STEP 2 ###############\n",
    "#*************************************#\n",
    "\n",
    "## Selecting these features as explained in the PDF: there is a very low difference in proportion within the negative \n",
    "## and positive datasets, likely meaning that they have little predictive accuracy. Indeed, removing them improves\n",
    "## the accuracy of the logistic regression. It is important to recognize that some stop words must not be removed \n",
    "## because the bigrams they form are very meaningful. That is why our selection of stop words is small.\n",
    "easy_stops = ['the', 'a', 'and', 'of', 'to', 'is', 'in', 'it', 'this', 'i', 'are', 'an', \"it's\", \"me\", \"they\",\"they're\", 'we', 'am'\\\n",
    "             'its', 'be', 'from', 'how', \"shan't\", 't', 'all', 'before', 'which', 'that', \"s\", 'up', 'y', \"she's\", \"shouldn't\"\\\n",
    "             ]\n",
    "\n",
    "#*************************************#\n",
    "################ STEP 3 ###############\n",
    "#*************************************#\n",
    "\n",
    "# Vectorizing the words with a log transformation because the data is skew. Logging will slightly\n",
    "# improve the predictive accuracy.\n",
    "train_vectorizer = TfidfVectorizer(stop_words = easy_stops, ngram_range = (1,2), max_features=max_feature_num, sublinear_tf = True)\n",
    "all_vecs = train_vectorizer.fit_transform(all_text)\n",
    "test_vecs = TfidfVectorizer(stop_words = easy_stops, ngram_range = (1,2), max_features=max_feature_num,\\\n",
    "sublinear_tf = True, vocabulary = train_vectorizer.vocabulary_).fit_transform(real_test_text)\n",
    "\n",
    "\n",
    "\n",
    "# The vectorizer\n",
    "train_vectorizer = TfidfVectorizer(stop_words = easy_stops, ngram_range = (1,2), max_features=max_feature_num,sublinear_tf = True)\n",
    "\n",
    "## The entire data set: transforming the training data to td-idf vectors \n",
    "all_vecs = train_vectorizer.fit_transform(all_text)\n",
    "\n",
    "## \n",
    "\n",
    "#*************************************#\n",
    "################ STEP 4 ###############\n",
    "#*************************************#\n",
    "\n",
    "# The logistic regression model (technically haven't fit yet, cv package will do that for us in the next step)\n",
    "clf_fit = LogisticRegression(penalty = 'l2', C = 18.80)\n",
    "\n",
    "\n",
    "#*************************************#\n",
    "################ STEP 5 ###############\n",
    "#*************************************#\n",
    "\n",
    "# Cross validating\n",
    "cv_results = cross_validate(clf_fit, all_vecs, all_lables, cv=5)\n",
    "print(np.mean(cv_results['test_score']))\n",
    "\n",
    "\n",
    "#*************************************#\n",
    "################ STEP 6 ###############\n",
    "#*************************************#\n",
    "\n",
    "\n",
    "### We do in fact take a look at the precision recall scores, but seeing as how the data split between the two class\n",
    "### is roughly around 50/50, all of the scores are very close to one another.\n",
    "\n",
    "#from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "#acc = accuracy_score(real_test_labels, test_pred)\n",
    "# pre, rec, f1, _ = precision_recall_fscore_support(real_test_labels, test_pred, average='macro')\n",
    "# print('acc', acc)\n",
    "# print('precision', pre)\n",
    "# print('rec', rec)\n",
    "# print('f1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE YOUR TRAINED MODEL\n",
    "After you have found the best model, save your trained model and other necessary components (e.g. vocabulary, vectorizer) to a file. I will load your model from the saved file and apply your trained model on some held-out test data. **At submission time, you are supposed to submit the saved model file, and I will NOT re-run your code to train your model; instead, I will directly use your trained model to run test (see notebook *cw1-test.ipybn*)**. \n",
    "\n",
    "Below is a sample code for saving the model (and other necessary components) obtained above, using the *pickle* package in Python. *You should adjust the code to save the necessary components for re-running your model!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['re', 'shan', 'she', 'shouldn'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "clf = LogisticRegression(penalty = 'l2', C = 18.80).fit(all_vecs, all_lables)\n",
    "train_vectorizer = TfidfVectorizer(stop_words = easy_stops, ngram_range = (1,2), max_features=max_feature_num, sublinear_tf = True)\n",
    "all_vecs = train_vectorizer.fit_transform(all_text)\n",
    "easy_stops = ['the', 'a', 'and', 'of', 'to', 'is', 'in', 'it', 'this', 'i', 'are', 'an', \"it's\", \"me\", \"they\",\"they're\", 'we', 'am'\\\n",
    "             'its', 'be', 'from', 'how', \"shan't\", 't', 'all', 'before', 'which', 'that', \"s\", 'up', 'y', \"she's\", \"shouldn't\"]\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'model': clf,\n",
    "    'vectorizer': TfidfVectorizer(stop_words = easy_stops, ngram_range = (1,2), max_features=max_feature_num,vocabulary=train_vectorizer.vocabulary_, sublinear_tf = True)\n",
    "}\n",
    "save_path = open(\"sample_trained_model.pickle\",\"wb\")\n",
    "pickle.dump(all_info_want_to_save, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *cw1-test.ipynb*, I provide a sample code to illustrate how to re-load your saved model and apply it to some test data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
