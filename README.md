# Projects
Contains code, pdf files, and data for a few projects, mainly to do with Natural Language Processing.
These projects feature usage of logistic regression, convolutional neural networks, reccurrent neural networks, etc.

## CW2:
This is a folder that contains the files for Propaganda Classification using convolutions neural nets in PyTorch.
   #### - pickle file of final convolutional neural network file 
   #### - cw2-train.ipynb - contains the main code for training and the rerpot
   #### - cw2-test.ipynb - contains side code for testing
   #### - glove vectors are large and can be found at https://nlp.stanford.edu/projects/glove/
   #### - Keep in mind that if you do not have a GPU, use Google Collab to run the code
   

## CW1:
This is a folder that contains the files for Sentiment Classification using a simpler ML algorithm.
Here, we end up using a simple logistic classification and implement a clever process involving a systematic fashion to pick and choose stop words to increase overall accuracy.
   #### - pickle file of final convolutional neural network file 
   #### - cwq-train-official.ipynb - contains the main code for training
   #### - cw1-test.ipynb - contains side code for testing
   #### - Report.pdf - contains the report for the project explaining methodology 
   #### - sample_trained_model.pickle - the model that is fit and can be run in cw1-test

## Project 1920:
This is a folder contains code for a project involving usage of PySpark.
   #### - project.py: project code 
   #### - test-driver.py: test input
   #### - remaining files are various text data relating to the enron dataset

## Image Classfication:
This folder contains code and a pdf file for a project using Keras on the Cifar Dataset. 
Images have 3 color channels and are broken down into ~9 categories. We build a Convolutional
Neural Net to Classify the images. 
   ### project_2020_official-ipynb: a jupyter notebook containing the project code
   ### question_sheet: a pdf file answering questions pertaining to optimization algorithms related to gradient descent (ADAM optimizer, RMSPropr, etc.) and answering some simple questions about Long-Short Term Memory Networks (LSTMs)
