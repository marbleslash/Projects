{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an MLP-based propaganda detector that uses BERT text representations as input\n",
    "In this notebook we will develop an MLP based propaganda detector, which uses BERT to vectoriz the input title-sentence pair. Note that the BERT model itself will *not* be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>711622457</td>\n",
       "      <td>UK: Labour MP Cites Ban of Robert Spencer &amp; Pa...</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>— Donald J. Trump (@realDonaldTrump) November ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>765913191</td>\n",
       "      <td>US Conference of Mayors Call For More Gun Conf...</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>The facts refute their arguments, but beyond t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9916</th>\n",
       "      <td>705409419</td>\n",
       "      <td>﻿Vatican Theologian Sacked for Questioning “Me...</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>Can we not see in Fr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>771879020</td>\n",
       "      <td>DOJ Surrenders: 3D Print Gun Files Are Protect...</td>\n",
       "      <td>propaganda</td>\n",
       "      <td>Cody finally won against the federal beast aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>758469195</td>\n",
       "      <td>American in China injured in 'sonic attack' si...</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>Some have permanent hearing loss or concussion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>787529309</td>\n",
       "      <td>The Last-Minute Character Assassination of Jud...</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>\"Senator Grassley must postpone the vote until...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>731063195</td>\n",
       "      <td>One Trillion Stars</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>Photo credit: Keilana, Roberta Mura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>790266787</td>\n",
       "      <td>Avenatti’s Freak Show</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>But I have never done that to her or to anyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>790266787</td>\n",
       "      <td>Avenatti’s Freak Show</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>An abused person wouldn’t do that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>730865684</td>\n",
       "      <td>Puerto Rico Hurricane Recovery Worsened By Nea...</td>\n",
       "      <td>non-propaganda</td>\n",
       "      <td>Furthermore, numerous homes have been built wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11464 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id                                      article_title  \\\n",
       "7520   711622457  UK: Labour MP Cites Ban of Robert Spencer & Pa...   \n",
       "6719   765913191  US Conference of Mayors Call For More Gun Conf...   \n",
       "9916   705409419  ﻿Vatican Theologian Sacked for Questioning “Me...   \n",
       "517    771879020  DOJ Surrenders: 3D Print Gun Files Are Protect...   \n",
       "9310   758469195  American in China injured in 'sonic attack' si...   \n",
       "...          ...                                                ...   \n",
       "4297   787529309  The Last-Minute Character Assassination of Jud...   \n",
       "9849   731063195                                 One Trillion Stars   \n",
       "1981   790266787                              Avenatti’s Freak Show   \n",
       "1994   790266787                              Avenatti’s Freak Show   \n",
       "4312   730865684  Puerto Rico Hurricane Recovery Worsened By Nea...   \n",
       "\n",
       "               label                                      sentence_text  \n",
       "7520  non-propaganda  — Donald J. Trump (@realDonaldTrump) November ...  \n",
       "6719      propaganda  The facts refute their arguments, but beyond t...  \n",
       "9916  non-propaganda                              Can we not see in Fr.  \n",
       "517       propaganda  Cody finally won against the federal beast aft...  \n",
       "9310  non-propaganda  Some have permanent hearing loss or concussion...  \n",
       "...              ...                                                ...  \n",
       "4297  non-propaganda  \"Senator Grassley must postpone the vote until...  \n",
       "9849  non-propaganda                Photo credit: Keilana, Roberta Mura  \n",
       "1981  non-propaganda    But I have never done that to her or to anyone.  \n",
       "1994  non-propaganda                 An abused person wouldn’t do that.  \n",
       "4312  non-propaganda  Furthermore, numerous homes have been built wi...  \n",
       "\n",
       "[11464 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from CW2 to train and test the model\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "df = pd.read_table('../CW2/coursework2_train.tsv')\n",
    "df = shuffle(df) # randomly shuffle data entries \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size: 11464, label type num: 2\n",
      "8227 3237\n"
     ]
    }
   ],
   "source": [
    "raw_labels = df.label.values.tolist()\n",
    "docs = df.sentence_text.values.tolist()\n",
    "titles = df.article_title.values.tolist()\n",
    "\n",
    "label_dic = {'non-propaganda':0, 'propaganda':1}\n",
    "\n",
    "assert len(docs) == len(raw_labels) == len(titles)\n",
    "labels = [label_dic[rl] for rl in raw_labels] # transfer raw labels (strings) to integer numbers\n",
    "print('total data size: {}, label type num: {}'.format(len(docs), len(label_dic)))\n",
    "\n",
    "np_num = len([ll for ll in labels if ll == 0])\n",
    "p_num = len([ll for ll in labels if ll == 1])\n",
    "print(np_num, p_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 6923, dev size 2217, test size 2324\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, dev and test\n",
    "import random\n",
    "\n",
    "train_ratio = 0.6\n",
    "dev_ratio = 0.2\n",
    "train_idx = []\n",
    "dev_idx = []\n",
    "test_idx = []\n",
    "for i in range(len(docs)):\n",
    "    rnd = random.random()\n",
    "    if rnd < train_ratio: train_idx.append(i)\n",
    "    elif rnd < train_ratio+dev_ratio: dev_idx.append(i)\n",
    "    else: test_idx.append(i)\n",
    "\n",
    "print('train size {}, dev size {}, test size {}'.format(len(train_idx), len(dev_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11464/11464 [04:37<00:00, 41.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# now we use the BERT model to vectorize all sentence-title pairs\n",
    "# !pip install transformers \n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpu = True\n",
    "bert_type = 'large'\n",
    "if bert_type == 'base':\n",
    "    bert_dim = 768\n",
    "else: \n",
    "    bert_dim = 1024\n",
    "use_titles = True # whether to consider the titles when making predictions\n",
    "bert_batch_size = 10\n",
    "\n",
    "all_input_vecs = []\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-{}-uncased'.format(bert_type))\n",
    "bert_model = BertModel.from_pretrained('bert-{}-uncased'.format(bert_type))\n",
    "\n",
    "if gpu:\n",
    "    bert_model.to('cuda')\n",
    "\n",
    "for i in tqdm(range(0, len(docs))):\n",
    "    if use_titles:\n",
    "        sent = [[titles[i], docs[i]]]\n",
    "    else:\n",
    "        sent = [docs[i]]\n",
    "    input_to_bert = bert_tokenizer.batch_encode_plus(sent)['input_ids']\n",
    "    input_to_bert = torch.tensor(input_to_bert)\n",
    "    if gpu: input_to_bert = input_to_bert.to('cuda')\n",
    "    words_vecs = bert_model(input_to_bert)[0][:,1:,:].squeeze().cpu().detach().numpy()\n",
    "    sent_vec = np.mean(words_vecs, axis=0)\n",
    "    # print(sent_vec.shape)\n",
    "    all_input_vecs.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11464, 1024)\n"
     ]
    }
   ],
   "source": [
    "all_input_vecs = np.array(all_input_vecs)\n",
    "print(all_input_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we define the RNN-based classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP_Clf(nn.Module):\n",
    "    def __init__(self, input_dim, cls_num, gpu):\n",
    "        super(MLP_Clf, self).__init__()\n",
    "        self.bert_dim = input_dim\n",
    "        # MLP structure: three layers in total, dim of the hidden layer is the same as input layer\n",
    "        self.fc1 = nn.Linear(self.bert_dim, self.bert_dim) \n",
    "        self.atv_fnc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.bert_dim, cls_num)\n",
    "        # use gpu or not\n",
    "        self.gpu = gpu\n",
    "        if self.gpu:\n",
    "            self.to('cuda')\n",
    "    def forward(self, input_batch, input_titles=None):\n",
    "        if self.gpu:\n",
    "            input_batch = input_batch.to('cuda')\n",
    "        logits = self.fc2( self.atv_fnc( self.fc1(input_batch) ) )\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the training data is inbalanced, we use simple down-sampling to balance the data\n",
    "# used to train the model\n",
    "import random\n",
    "import numpy as np\n",
    "def down_sample():\n",
    "    np_idx = [i for i in train_idx if labels[i]==0]\n",
    "    p_idx = [i for i in train_idx if labels[i]==1]\n",
    "    each_cat_num = min(len(np_idx), len(p_idx))\n",
    "    random.shuffle(np_idx)\n",
    "    random.shuffle(p_idx)\n",
    "    wanted_idx = np_idx[:each_cat_num] + p_idx[:each_cat_num]\n",
    "    random.shuffle(wanted_idx)\n",
    "    return wanted_idx\n",
    "    \n",
    "wanted_idx = down_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our MLP model, we first check the performance of some simple baseline methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> the macro-F1 of random baseline on dev set is 0.47265816526516913\n"
     ]
    }
   ],
   "source": [
    "# random baseline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "rand_pred = [random.randint(0,1) for i in range(len(test_idx))]\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(np.array(labels)[test_idx], rand_pred,average='macro')\n",
    "print('\\n---> the macro-F1 of random baseline on dev set is {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> the macro-F1 of majority baseline on dev set is 0.41608040201005025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cim/staff/uhac002/PycharmProjects/ScratchPad/venv_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# majority baseline\n",
    "major_pred = [0]*len(test_idx)\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(np.array(labels)[test_idx], major_pred, average='macro')\n",
    "print('\\n---> the macro-F1 of majority baseline on dev set is {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start to train our MLP model with BERT vectors as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_Clf(bert_dim, len(label_dic), gpu)\n",
    "loss_fnc = torch.nn.CrossEntropyLoss() # cross entropy loss\n",
    "\n",
    "# hyper parameters\n",
    "n_epochs = 100 # number of epoch (i.e. number of iterations)\n",
    "batch_size = 32\n",
    "lr = 1e-4 # initial learning rate\n",
    "\n",
    "# init optimizer and scheduler (lr adjustor)\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr) # use Adam as the optimizer\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8) # after each epoch, the learning rate is discounted to its 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> before training, the macro-F1 on dev set is 0.727675023081504\n",
      "pred 1 percent 0.2372575552548489\n"
     ]
    }
   ],
   "source": [
    "# before we train the model, we first look at its initial performance on the test set\n",
    "# without performing any training\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "    model.eval() # let the model know that it in test mode, i.e. no gradient and no dropout\n",
    "    predictions = []\n",
    "    for i in range(0,len(dev_idx),batch_size):\n",
    "        idx = dev_idx[i:i+batch_size] \n",
    "        vecs = torch.tensor(all_input_vecs[idx])\n",
    "        if gpu: vecs = vecs.to('cuda')\n",
    "        y_pred = model(vecs).cpu().detach().numpy()\n",
    "        pred_labels = [np.argmax(entry) for entry in y_pred]\n",
    "        predictions += pred_labels\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(np.array(labels)[dev_idx], predictions,average='macro')\n",
    "    print('\\n---> before training, the macro-F1 on dev set is {}'.format(f1))\n",
    "    print('pred 1 percent', np.sum(predictions)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:43,  2.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 0 loss====== 0.30748448\n",
      "\n",
      "---> after 0 epochs, the macro-F1 on dev set is 0.6771713994661194\n",
      "pred 1 percent 0.13757329724853407\n",
      "learning rate 6.400000000000001e-05\n",
      "best model updated; new best macro-F1 0.6771713994661194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/100 [00:00<00:42,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 1 loss====== 0.30280167\n",
      "\n",
      "---> after 1 epochs, the macro-F1 on dev set is 0.676318329167801\n",
      "pred 1 percent 0.13847541723049164\n",
      "learning rate 6.400000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [00:01<00:42,  2.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 2 loss====== 0.29767308\n",
      "\n",
      "---> after 2 epochs, the macro-F1 on dev set is 0.6768365294818138\n",
      "pred 1 percent 0.13937753721244925\n",
      "learning rate 6.400000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 4/100 [00:01<00:42,  2.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 3 loss====== 0.29257727\n",
      "\n",
      "---> after 3 epochs, the macro-F1 on dev set is 0.6782922677593525\n",
      "pred 1 percent 0.14073071718538566\n",
      "learning rate 6.400000000000001e-05\n",
      "best model updated; new best macro-F1 0.6782922677593525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 5/100 [00:02<00:42,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 4 loss====== 0.28747344\n",
      "\n",
      "---> after 4 epochs, the macro-F1 on dev set is 0.6788032810938456\n",
      "pred 1 percent 0.14163283716734326\n",
      "learning rate 6.400000000000001e-05\n",
      "best model updated; new best macro-F1 0.6788032810938456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 6/100 [00:02<00:42,  2.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 5 loss====== 0.28288373\n",
      "\n",
      "---> after 5 epochs, the macro-F1 on dev set is 0.6845820474095476\n",
      "pred 1 percent 0.14839873703202525\n",
      "learning rate 5.120000000000001e-05\n",
      "best model updated; new best macro-F1 0.6845820474095476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 7/100 [00:03<00:46,  1.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 6 loss====== 0.2791812\n",
      "\n",
      "---> after 6 epochs, the macro-F1 on dev set is 0.6845820474095476\n",
      "pred 1 percent 0.14839873703202525\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 8/100 [00:03<00:44,  2.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 7 loss====== 0.2750004\n",
      "\n",
      "---> after 7 epochs, the macro-F1 on dev set is 0.6837240784808898\n",
      "pred 1 percent 0.14930085701398285\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 9/100 [00:04<00:43,  2.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 8 loss====== 0.27085644\n",
      "\n",
      "---> after 8 epochs, the macro-F1 on dev set is 0.6837833933793614\n",
      "pred 1 percent 0.15065403698691926\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 10/100 [00:04<00:41,  2.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 9 loss====== 0.2667446\n",
      "\n",
      "---> after 9 epochs, the macro-F1 on dev set is 0.6851803734364614\n",
      "pred 1 percent 0.15200721695985567\n",
      "learning rate 5.120000000000001e-05\n",
      "best model updated; new best macro-F1 0.6851803734364614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 11/100 [00:05<00:45,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 10 loss====== 0.26258966\n",
      "\n",
      "---> after 10 epochs, the macro-F1 on dev set is 0.683355483416487\n",
      "pred 1 percent 0.15110509697789806\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 12/100 [00:05<00:44,  1.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 11 loss====== 0.25853106\n",
      "\n",
      "---> after 11 epochs, the macro-F1 on dev set is 0.6820137693631669\n",
      "pred 1 percent 0.15110509697789806\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 13/100 [00:06<00:50,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 12 loss====== 0.25446206\n",
      "\n",
      "---> after 12 epochs, the macro-F1 on dev set is 0.6829280387268635\n",
      "pred 1 percent 0.15155615696887687\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 14/100 [00:06<00:45,  1.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 13 loss====== 0.25044754\n",
      "\n",
      "---> after 13 epochs, the macro-F1 on dev set is 0.6838407154510847\n",
      "pred 1 percent 0.15200721695985567\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 15/100 [00:07<00:49,  1.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 14 loss====== 0.24642026\n",
      "\n",
      "---> after 14 epochs, the macro-F1 on dev set is 0.6838407154510847\n",
      "pred 1 percent 0.15200721695985567\n",
      "learning rate 5.120000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 16/100 [00:08<00:50,  1.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 15 loss====== 0.24334988\n",
      "\n",
      "---> after 15 epochs, the macro-F1 on dev set is 0.6952530775575037\n",
      "pred 1 percent 0.16914749661705006\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.6952530775575037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 17/100 [00:09<00:53,  1.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 16 loss====== 0.24044947\n",
      "\n",
      "---> after 16 epochs, the macro-F1 on dev set is 0.6956921127652835\n",
      "pred 1 percent 0.17004961659900766\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.6956921127652835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 18/100 [00:09<00:48,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 17 loss====== 0.23709142\n",
      "\n",
      "---> after 17 epochs, the macro-F1 on dev set is 0.6965606520256518\n",
      "pred 1 percent 0.17050067658998647\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.6965606520256518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 19/100 [00:10<00:49,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 18 loss====== 0.23374668\n",
      "\n",
      "---> after 18 epochs, the macro-F1 on dev set is 0.6961291728364979\n",
      "pred 1 percent 0.17095173658096527\n",
      "learning rate 4.096000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 20/100 [00:10<00:51,  1.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 19 loss====== 0.23047438\n",
      "\n",
      "---> after 19 epochs, the macro-F1 on dev set is 0.695698134544251\n",
      "pred 1 percent 0.17140279657194407\n",
      "learning rate 4.096000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 21/100 [00:11<00:47,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 20 loss====== 0.227193\n",
      "\n",
      "---> after 20 epochs, the macro-F1 on dev set is 0.6969974137387245\n",
      "pred 1 percent 0.17275597654488048\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.6969974137387245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 22/100 [00:11<00:47,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 21 loss====== 0.22398958\n",
      "\n",
      "---> after 21 epochs, the macro-F1 on dev set is 0.6978602376813302\n",
      "pred 1 percent 0.17320703653585928\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.6978602376813302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 23/100 [00:12<00:47,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 22 loss====== 0.22081774\n",
      "\n",
      "---> after 22 epochs, the macro-F1 on dev set is 0.698292296585995\n",
      "pred 1 percent 0.17275597654488048\n",
      "learning rate 4.096000000000001e-05\n",
      "best model updated; new best macro-F1 0.698292296585995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 24/100 [00:13<00:43,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 23 loss====== 0.21763083\n",
      "\n",
      "---> after 23 epochs, the macro-F1 on dev set is 0.6978602376813302\n",
      "pred 1 percent 0.17320703653585928\n",
      "learning rate 4.096000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 25/100 [00:13<00:44,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 24 loss====== 0.2145507\n",
      "\n",
      "---> after 24 epochs, the macro-F1 on dev set is 0.6969974137387245\n",
      "pred 1 percent 0.17275597654488048\n",
      "learning rate 4.096000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 26/100 [00:14<00:42,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 25 loss====== 0.21233521\n",
      "\n",
      "---> after 25 epochs, the macro-F1 on dev set is 0.7086516200467504\n",
      "pred 1 percent 0.20162381596752368\n",
      "learning rate 3.276800000000001e-05\n",
      "best model updated; new best macro-F1 0.7086516200467504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 27/100 [00:14<00:40,  1.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 26 loss====== 0.20965351\n",
      "\n",
      "---> after 26 epochs, the macro-F1 on dev set is 0.7078426188227888\n",
      "pred 1 percent 0.20117275597654488\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 28/100 [00:15<00:41,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 27 loss====== 0.2069905\n",
      "\n",
      "---> after 27 epochs, the macro-F1 on dev set is 0.7090278196647699\n",
      "pred 1 percent 0.2025259359494813\n",
      "learning rate 3.276800000000001e-05\n",
      "best model updated; new best macro-F1 0.7090278196647699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 29/100 [00:16<00:42,  1.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 28 loss====== 0.20437409\n",
      "\n",
      "---> after 28 epochs, the macro-F1 on dev set is 0.7090278196647699\n",
      "pred 1 percent 0.2025259359494813\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 30/100 [00:16<00:38,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 29 loss====== 0.20178764\n",
      "\n",
      "---> after 29 epochs, the macro-F1 on dev set is 0.7094024006604047\n",
      "pred 1 percent 0.2034280559314389\n",
      "learning rate 3.276800000000001e-05\n",
      "best model updated; new best macro-F1 0.7094024006604047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [00:17<00:40,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 30 loss====== 0.19924203\n",
      "\n",
      "---> after 30 epochs, the macro-F1 on dev set is 0.7090278196647699\n",
      "pred 1 percent 0.2025259359494813\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 32/100 [00:17<00:41,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 31 loss====== 0.19671145\n",
      "\n",
      "---> after 31 epochs, the macro-F1 on dev set is 0.7090278196647699\n",
      "pred 1 percent 0.2025259359494813\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 33/100 [00:18<00:41,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 32 loss====== 0.19422948\n",
      "\n",
      "---> after 32 epochs, the macro-F1 on dev set is 0.7094594122589628\n",
      "pred 1 percent 0.2020748759585025\n",
      "learning rate 3.276800000000001e-05\n",
      "best model updated; new best macro-F1 0.7094594122589628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 34/100 [00:18<00:37,  1.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 33 loss====== 0.19176729\n",
      "\n",
      "---> after 33 epochs, the macro-F1 on dev set is 0.7074118397065239\n",
      "pred 1 percent 0.20162381596752368\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 35/100 [00:19<00:34,  1.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 34 loss====== 0.18932223\n",
      "\n",
      "---> after 34 epochs, the macro-F1 on dev set is 0.7094594122589628\n",
      "pred 1 percent 0.2020748759585025\n",
      "learning rate 3.276800000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 36/100 [00:20<00:37,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 35 loss====== 0.18739851\n",
      "\n",
      "---> after 35 epochs, the macro-F1 on dev set is 0.7262087065964207\n",
      "pred 1 percent 0.2313937753721245\n",
      "learning rate 2.621440000000001e-05\n",
      "best model updated; new best macro-F1 0.7262087065964207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 37/100 [00:20<00:33,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 36 loss====== 0.18510456\n",
      "\n",
      "---> after 36 epochs, the macro-F1 on dev set is 0.7266436990027199\n",
      "pred 1 percent 0.2309427153811457\n",
      "learning rate 2.621440000000001e-05\n",
      "best model updated; new best macro-F1 0.7266436990027199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 38/100 [00:21<00:35,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 37 loss====== 0.1830067\n",
      "\n",
      "---> after 37 epochs, the macro-F1 on dev set is 0.72588726064659\n",
      "pred 1 percent 0.2304916553901669\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 39/100 [00:21<00:35,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 38 loss====== 0.18098344\n",
      "\n",
      "---> after 38 epochs, the macro-F1 on dev set is 0.72588726064659\n",
      "pred 1 percent 0.2304916553901669\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 40/100 [00:22<00:33,  1.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 39 loss====== 0.1789804\n",
      "\n",
      "---> after 39 epochs, the macro-F1 on dev set is 0.7255644682115271\n",
      "pred 1 percent 0.22958953540820928\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 41/100 [00:22<00:34,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 40 loss====== 0.1769818\n",
      "\n",
      "---> after 40 epochs, the macro-F1 on dev set is 0.7248056139776455\n",
      "pred 1 percent 0.22913847541723048\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 42/100 [00:23<00:30,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 41 loss====== 0.17500465\n",
      "\n",
      "---> after 41 epochs, the macro-F1 on dev set is 0.7229564525980348\n",
      "pred 1 percent 0.2273342354533153\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 43/100 [00:23<00:33,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 42 loss====== 0.17310604\n",
      "\n",
      "---> after 42 epochs, the macro-F1 on dev set is 0.7229564525980348\n",
      "pred 1 percent 0.2273342354533153\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 44/100 [00:24<00:33,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 43 loss====== 0.17119615\n",
      "\n",
      "---> after 43 epochs, the macro-F1 on dev set is 0.7229564525980348\n",
      "pred 1 percent 0.2273342354533153\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 45/100 [00:25<00:30,  1.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 44 loss====== 0.16930924\n",
      "\n",
      "---> after 44 epochs, the macro-F1 on dev set is 0.722193055798609\n",
      "pred 1 percent 0.2268831754623365\n",
      "learning rate 2.621440000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 46/100 [00:25<00:30,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 45 loss====== 0.16769549\n",
      "\n",
      "---> after 45 epochs, the macro-F1 on dev set is 0.7289162426605138\n",
      "pred 1 percent 0.2408660351826793\n",
      "learning rate 2.097152000000001e-05\n",
      "best model updated; new best macro-F1 0.7289162426605138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 47/100 [00:26<00:31,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 46 loss====== 0.1659122\n",
      "\n",
      "---> after 46 epochs, the macro-F1 on dev set is 0.7289162426605138\n",
      "pred 1 percent 0.2408660351826793\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 48/100 [00:27<00:32,  1.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 47 loss====== 0.1643398\n",
      "\n",
      "---> after 47 epochs, the macro-F1 on dev set is 0.7284822528687855\n",
      "pred 1 percent 0.2413170951736581\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 49/100 [00:27<00:29,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 48 loss====== 0.16277102\n",
      "\n",
      "---> after 48 epochs, the macro-F1 on dev set is 0.7284822528687855\n",
      "pred 1 percent 0.2413170951736581\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 50/100 [00:28<00:29,  1.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 49 loss====== 0.16125564\n",
      "\n",
      "---> after 49 epochs, the macro-F1 on dev set is 0.7289162426605138\n",
      "pred 1 percent 0.2408660351826793\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 51/100 [00:28<00:26,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 50 loss====== 0.15972655\n",
      "\n",
      "---> after 50 epochs, the macro-F1 on dev set is 0.7289162426605138\n",
      "pred 1 percent 0.2408660351826793\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 52/100 [00:29<00:26,  1.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 51 loss====== 0.15822044\n",
      "\n",
      "---> after 51 epochs, the macro-F1 on dev set is 0.7293505815212545\n",
      "pred 1 percent 0.2404149751917005\n",
      "learning rate 2.097152000000001e-05\n",
      "best model updated; new best macro-F1 0.7293505815212545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 53/100 [00:29<00:24,  1.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 52 loss====== 0.1567276\n",
      "\n",
      "---> after 52 epochs, the macro-F1 on dev set is 0.7293505815212545\n",
      "pred 1 percent 0.2404149751917005\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 54/100 [00:30<00:23,  1.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 53 loss====== 0.15527654\n",
      "\n",
      "---> after 53 epochs, the macro-F1 on dev set is 0.7289162426605138\n",
      "pred 1 percent 0.2408660351826793\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 55/100 [00:30<00:24,  1.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 54 loss====== 0.15377992\n",
      "\n",
      "---> after 54 epochs, the macro-F1 on dev set is 0.728173844919173\n",
      "pred 1 percent 0.2404149751917005\n",
      "learning rate 2.097152000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 56/100 [00:31<00:25,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 55 loss====== 0.15264079\n",
      "\n",
      "---> after 55 epochs, the macro-F1 on dev set is 0.7291386682956628\n",
      "pred 1 percent 0.2467298150654037\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 57/100 [00:31<00:24,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 56 loss====== 0.151233\n",
      "\n",
      "---> after 56 epochs, the macro-F1 on dev set is 0.7291386682956628\n",
      "pred 1 percent 0.2467298150654037\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 58/100 [00:32<00:23,  1.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 57 loss====== 0.15000758\n",
      "\n",
      "---> after 57 epochs, the macro-F1 on dev set is 0.7291386682956628\n",
      "pred 1 percent 0.2467298150654037\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 59/100 [00:33<00:23,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 58 loss====== 0.14879063\n",
      "\n",
      "---> after 58 epochs, the macro-F1 on dev set is 0.7307399772112046\n",
      "pred 1 percent 0.2462787550744249\n",
      "learning rate 1.677721600000001e-05\n",
      "best model updated; new best macro-F1 0.7307399772112046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 60/100 [00:33<00:22,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 59 loss====== 0.1476021\n",
      "\n",
      "---> after 59 epochs, the macro-F1 on dev set is 0.7311741223658321\n",
      "pred 1 percent 0.2458276950834461\n",
      "learning rate 1.677721600000001e-05\n",
      "best model updated; new best macro-F1 0.7311741223658321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 61/100 [00:34<00:20,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 60 loss====== 0.14641182\n",
      "\n",
      "---> after 60 epochs, the macro-F1 on dev set is 0.7307399772112046\n",
      "pred 1 percent 0.2462787550744249\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 62/100 [00:34<00:19,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 61 loss====== 0.14523661\n",
      "\n",
      "---> after 61 epochs, the macro-F1 on dev set is 0.7300053142022054\n",
      "pred 1 percent 0.2458276950834461\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 63/100 [00:35<00:19,  1.90it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 62 loss====== 0.1440677\n",
      "\n",
      "---> after 62 epochs, the macro-F1 on dev set is 0.7307399772112046\n",
      "pred 1 percent 0.2462787550744249\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 64/100 [00:35<00:20,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 63 loss====== 0.14292812\n",
      "\n",
      "---> after 63 epochs, the macro-F1 on dev set is 0.7307399772112046\n",
      "pred 1 percent 0.2462787550744249\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 65/100 [00:36<00:21,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 64 loss====== 0.14179865\n",
      "\n",
      "---> after 64 epochs, the macro-F1 on dev set is 0.7304391493684934\n",
      "pred 1 percent 0.2453766350924673\n",
      "learning rate 1.677721600000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 66/100 [00:36<00:19,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 65 loss====== 0.14096023\n",
      "\n",
      "---> after 65 epochs, the macro-F1 on dev set is 0.7290422343613834\n",
      "pred 1 percent 0.2395128552097429\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 67/100 [00:37<00:17,  1.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 66 loss====== 0.13984899\n",
      "\n",
      "---> after 66 epochs, the macro-F1 on dev set is 0.7290422343613834\n",
      "pred 1 percent 0.2395128552097429\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 68/100 [00:38<00:18,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 67 loss====== 0.1388902\n",
      "\n",
      "---> after 67 epochs, the macro-F1 on dev set is 0.7282982061153022\n",
      "pred 1 percent 0.23906179521876408\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 69/100 [00:38<00:18,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 68 loss====== 0.13794458\n",
      "\n",
      "---> after 68 epochs, the macro-F1 on dev set is 0.7282982061153022\n",
      "pred 1 percent 0.23906179521876408\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 70/100 [00:39<00:18,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 69 loss====== 0.13701569\n",
      "\n",
      "---> after 69 epochs, the macro-F1 on dev set is 0.7290422343613834\n",
      "pred 1 percent 0.2395128552097429\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 71/100 [00:40<00:18,  1.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 70 loss====== 0.13609919\n",
      "\n",
      "---> after 70 epochs, the macro-F1 on dev set is 0.7282982061153022\n",
      "pred 1 percent 0.23906179521876408\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 72/100 [00:40<00:17,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 71 loss====== 0.13519724\n",
      "\n",
      "---> after 71 epochs, the macro-F1 on dev set is 0.7302203116032904\n",
      "pred 1 percent 0.2395128552097429\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 73/100 [00:41<00:17,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 72 loss====== 0.13428384\n",
      "\n",
      "---> after 72 epochs, the macro-F1 on dev set is 0.728421691752149\n",
      "pred 1 percent 0.2377086152458277\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 74/100 [00:42<00:16,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 73 loss====== 0.13338229\n",
      "\n",
      "---> after 73 epochs, the macro-F1 on dev set is 0.7296024670054004\n",
      "pred 1 percent 0.2377086152458277\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 75/100 [00:42<00:15,  1.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 74 loss====== 0.13250117\n",
      "\n",
      "---> after 74 epochs, the macro-F1 on dev set is 0.7288564763436232\n",
      "pred 1 percent 0.2372575552548489\n",
      "learning rate 1.3421772800000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 76/100 [00:43<00:13,  1.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 75 loss====== 0.13178699\n",
      "\n",
      "---> after 75 epochs, the macro-F1 on dev set is 0.7244800828147303\n",
      "pred 1 percent 0.2282363554352729\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 77/100 [00:43<00:13,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 76 loss====== 0.13096201\n",
      "\n",
      "---> after 76 epochs, the macro-F1 on dev set is 0.7237187939000154\n",
      "pred 1 percent 0.2277852954442941\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 78/100 [00:44<00:13,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 77 loss====== 0.13021281\n",
      "\n",
      "---> after 77 epochs, the macro-F1 on dev set is 0.7241531849842202\n",
      "pred 1 percent 0.2273342354533153\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 79/100 [00:45<00:13,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 78 loss====== 0.12947424\n",
      "\n",
      "---> after 78 epochs, the macro-F1 on dev set is 0.7245879432486211\n",
      "pred 1 percent 0.2268831754623365\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 80/100 [00:45<00:13,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 79 loss====== 0.12875609\n",
      "\n",
      "---> after 79 epochs, the macro-F1 on dev set is 0.7245879432486211\n",
      "pred 1 percent 0.2268831754623365\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 81/100 [00:46<00:13,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 80 loss====== 0.12804744\n",
      "\n",
      "---> after 80 epochs, the macro-F1 on dev set is 0.723390499523615\n",
      "pred 1 percent 0.2268831754623365\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 82/100 [00:47<00:12,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 81 loss====== 0.12733264\n",
      "\n",
      "---> after 81 epochs, the macro-F1 on dev set is 0.7238249134957446\n",
      "pred 1 percent 0.2264321154713577\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 83/100 [00:47<00:11,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 82 loss====== 0.12661515\n",
      "\n",
      "---> after 82 epochs, the macro-F1 on dev set is 0.7238249134957446\n",
      "pred 1 percent 0.2264321154713577\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 84/100 [00:48<00:09,  1.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 83 loss====== 0.12591201\n",
      "\n",
      "---> after 83 epochs, the macro-F1 on dev set is 0.7242596958750622\n",
      "pred 1 percent 0.2259810554803789\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 85/100 [00:49<00:09,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 84 loss====== 0.12521186\n",
      "\n",
      "---> after 84 epochs, the macro-F1 on dev set is 0.7242596958750622\n",
      "pred 1 percent 0.2259810554803789\n",
      "learning rate 1.0737418240000007e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 86/100 [00:49<00:08,  1.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 85 loss====== 0.12455391\n",
      "\n",
      "---> after 85 epochs, the macro-F1 on dev set is 0.7219228881496429\n",
      "pred 1 percent 0.21966621560667568\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 87/100 [00:50<00:08,  1.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 86 loss====== 0.12397652\n",
      "\n",
      "---> after 86 epochs, the macro-F1 on dev set is 0.7219228881496429\n",
      "pred 1 percent 0.21966621560667568\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 88/100 [00:50<00:07,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 87 loss====== 0.1233924\n",
      "\n",
      "---> after 87 epochs, the macro-F1 on dev set is 0.7219228881496429\n",
      "pred 1 percent 0.21966621560667568\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 89/100 [00:51<00:06,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 88 loss====== 0.122815564\n",
      "\n",
      "---> after 88 epochs, the macro-F1 on dev set is 0.7211484339722767\n",
      "pred 1 percent 0.21921515561569688\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 90/100 [00:52<00:06,  1.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 89 loss====== 0.12224046\n",
      "\n",
      "---> after 89 epochs, the macro-F1 on dev set is 0.7211484339722767\n",
      "pred 1 percent 0.21921515561569688\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 91/100 [00:52<00:05,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 90 loss====== 0.12167825\n",
      "\n",
      "---> after 90 epochs, the macro-F1 on dev set is 0.7211484339722767\n",
      "pred 1 percent 0.21921515561569688\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 92/100 [00:53<00:05,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 91 loss====== 0.121120594\n",
      "\n",
      "---> after 91 epochs, the macro-F1 on dev set is 0.7211484339722767\n",
      "pred 1 percent 0.21921515561569688\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 93/100 [00:54<00:04,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 92 loss====== 0.12056071\n",
      "\n",
      "---> after 92 epochs, the macro-F1 on dev set is 0.7211484339722767\n",
      "pred 1 percent 0.21921515561569688\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 94/100 [00:54<00:03,  1.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 93 loss====== 0.1200108\n",
      "\n",
      "---> after 93 epochs, the macro-F1 on dev set is 0.720372882022251\n",
      "pred 1 percent 0.21876409562471807\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 95/100 [00:55<00:03,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 94 loss====== 0.11945911\n",
      "\n",
      "---> after 94 epochs, the macro-F1 on dev set is 0.720372882022251\n",
      "pred 1 percent 0.21876409562471807\n",
      "learning rate 8.589934592000006e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 96/100 [00:56<00:02,  1.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 95 loss====== 0.11888606\n",
      "\n",
      "---> after 95 epochs, the macro-F1 on dev set is 0.7184731086273523\n",
      "pred 1 percent 0.2169598556608029\n",
      "learning rate 6.871947673600004e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 97/100 [00:57<00:02,  1.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 96 loss====== 0.11845411\n",
      "\n",
      "---> after 96 epochs, the macro-F1 on dev set is 0.7184731086273523\n",
      "pred 1 percent 0.2169598556608029\n",
      "learning rate 6.871947673600004e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 98/100 [00:57<00:01,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 97 loss====== 0.11798878\n",
      "\n",
      "---> after 97 epochs, the macro-F1 on dev set is 0.7184731086273523\n",
      "pred 1 percent 0.2169598556608029\n",
      "learning rate 6.871947673600004e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 99/100 [00:58<00:00,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 98 loss====== 0.117530756\n",
      "\n",
      "---> after 98 epochs, the macro-F1 on dev set is 0.7184731086273523\n",
      "pred 1 percent 0.2169598556608029\n",
      "learning rate 6.871947673600004e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.68it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======epoch 99 loss====== 0.11708305\n",
      "\n",
      "---> after 99 epochs, the macro-F1 on dev set is 0.7184731086273523\n",
      "pred 1 percent 0.2169598556608029\n",
      "learning rate 6.871947673600004e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_f1 = -1.\n",
    "best_model = None\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch_i in tqdm(range(n_epochs)):\n",
    "    # the inner loop is over the batches in the dataset\n",
    "    model.train() # let pytorch know that gradients should be computed, so as to update the model\n",
    "    ep_loss = []\n",
    "    sample_idx = down_sample()\n",
    "    for i in range(0,len(train_idx),batch_size):\n",
    "        # Step 0: Get the data\n",
    "        idx = train_idx[i:i+batch_size] \n",
    "        if len(idx) == 0: break\n",
    "        # print(idx)\n",
    "        vecs = torch.tensor(all_input_vecs[idx])\n",
    "        if gpu: vecs = vecs.to('cuda')\n",
    "        target_labels = list(np.array(labels)[idx])\n",
    "        # print(sents[0])\n",
    "        y_target = torch.tensor(target_labels, dtype=torch.int64).squeeze()\n",
    "        if gpu:\n",
    "            y_target = y_target.to('cuda')\n",
    "        \n",
    "        # Step 1: Clear the gradients \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Step 2: Compute the forward pass of the model\n",
    "        y_pred = model(vecs)\n",
    "        # print(y_pred)\n",
    "        yp = y_pred.cpu().detach().numpy()\n",
    "        pred_labels = [np.argmax(entry) for entry in yp]\n",
    "        # print('pred labels', pred_labels)\n",
    "        # print('true labels', y_target)\n",
    "\n",
    "        # Step 3: Compute the loss value that we wish to optimize\n",
    "        loss = loss_fnc(y_pred, y_target)\n",
    "        # print(loss)\n",
    "        ep_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        # Step 4: Propagate the loss signal backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Step 5: Trigger the optimizer to perform one update\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('\\n======epoch {} loss======'.format(epoch_i),np.mean(ep_loss))\n",
    "    \n",
    "    # after each epoch, we can test the model's performance on the test set\n",
    "    with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "        model.eval() # let the model know that it in test mode, i.e. no gradient and no dropout\n",
    "        predictions = []\n",
    "        for i in range(0,len(dev_idx),batch_size):\n",
    "            idx = dev_idx[i:i+batch_size] \n",
    "            vecs = torch.tensor(all_input_vecs[idx])\n",
    "            if gpu: vecs = vecs.to('cuda')\n",
    "            y_pred = model(vecs).cpu().detach().numpy()\n",
    "            pred_labels = [np.argmax(entry) for entry in y_pred]\n",
    "            predictions += pred_labels\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(np.array(labels)[dev_idx], predictions,average='macro')\n",
    "        print('\\n---> after {} epochs, the macro-F1 on dev set is {}'.format(epoch_i,f1))\n",
    "        print('pred 1 percent', np.sum(predictions)/len(predictions))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print('learning rate', param_group['lr'])\n",
    "        \n",
    "        # save the best model\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            print('best model updated; new best macro-F1',f1)\n",
    "    \n",
    "    # (optional) adjust learning rate according to the scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--->  the macro-F1 on test set is 0.7126365010256823\n",
      "pred 1 percent 0.2452667814113597\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "with torch.no_grad(): # let pytorch know that no gradient should be computed\n",
    "    model.eval() # let the model know that it in test mode, i.e. no gradient and no dropout\n",
    "    predictions = []\n",
    "    for i in range(0,len(test_idx),batch_size):\n",
    "        idx = test_idx[i:i+batch_size] \n",
    "        vecs = torch.tensor(all_input_vecs[idx])\n",
    "        if gpu: vecs = vecs.to('cuda')\n",
    "        y_pred = model(vecs).cpu().detach().numpy()\n",
    "        pred_labels = [np.argmax(entry) for entry in y_pred]\n",
    "        predictions += pred_labels\n",
    "    pre, rec, f1, _ = precision_recall_fscore_support(np.array(labels)[test_idx], predictions,average='macro')\n",
    "    print('\\n--->  the macro-F1 on test set is {}'.format(f1))\n",
    "    print('pred 1 percent', np.sum(predictions)/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save your trained model, you may uncomment the line below\n",
    "# torch.save(best_model, 'bert_pgd_base_wTitle.state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
